{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12881d28-4fd1-4b67-9502-ae97c4822a80",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf71e48e-deb6-4337-9b5e-ee405bd88152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd18deed-9d0d-4861-98b3-b7f9d32be457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.utils import shuffle\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Config, T5ForConditionalGeneration, T5Tokenizer, get_linear_schedule_with_warmup\n",
    "import copy\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics.text import MatchErrorRate, BLEUScore\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802210f-f08c-4132-8898-f33da697256f",
   "metadata": {},
   "source": [
    "# Prepare the datasetT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96fb61c-8ac9-4650-b4cb-91e03ac0f6de",
   "metadata": {},
   "source": [
    "### Creating directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6515d7d-63b5-43b4-8d2c-7af282b89908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer  model  dataset\n"
     ]
    }
   ],
   "source": [
    "DIR=\"t5\"\n",
    "\n",
    "!mkdir -p \"{DIR}/dataset\"\n",
    "!mkdir -p \"{DIR}/model\"\n",
    "!mkdir -p \"{DIR}/tokenizer\"\n",
    "\n",
    "!ls -r \"{DIR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94054d31-7c90-459f-99f3-6976c22bde0c",
   "metadata": {},
   "source": [
    "### Getting SQUAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8ea10f-c3b6-4401-8b04-db754f37ca67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16476db84d7f426c873923dcdba4e911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eab7a129d5f469fa2899f5f3d955829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59915ff5660b4de3b9081eea8d53911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae02fada719e42c4a5b8e097a12fb32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd29400a0024168aaaf7a827a80204c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d95d9f18ce41c495ad4a4058b29ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8759bcc1670a4fdebca3fa9fe7e15119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_name = \"squad\"\n",
    "ds = load_dataset(ds_name)\n",
    "\n",
    "train_testvalid = ds['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Split the 20% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "ds_ = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a00b83-6cf3-4ad6-9dbd-2b5088c90bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 8760\n",
      "}),\n",
      " 'train': Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 70079\n",
      "}),\n",
      " 'valid': Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 8760\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "pprint(ds_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a70d7-1555-45ff-a2a6-f7d3b5d24e2b",
   "metadata": {},
   "source": [
    "### Visualizing a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c8fbd0-15ed-45de-a033-7a77408e9a36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': {'answer_start': [38], 'text': ['Britain and France']},\n",
      " 'context': 'News of this arrived in Europe, where Britain and France '\n",
      "            'unsuccessfully attempted to negotiate a solution. The two nations '\n",
      "            'eventually dispatched regular troops to North America to enforce '\n",
      "            'their claims. The first British action was the assault on Acadia '\n",
      "            'on 16 June 1755 in the Battle of Fort BeausÃ©jour, which was '\n",
      "            'immediately followed by their expulsion of the Acadians. In July '\n",
      "            'British Major General Edward Braddock led about 2,000 army troops '\n",
      "            'and provincial militia on an expedition to retake Fort Duquesne, '\n",
      "            'but the expedition ended in disastrous defeat. In further action, '\n",
      "            'Admiral Edward Boscawen fired on the French ship Alcide on 8 June '\n",
      "            '1755, capturing it and two troop ships. In September 1755, French '\n",
      "            'and British troops met in the inconclusive Battle of Lake George.',\n",
      " 'id': '572ea92e03f98919007568d1',\n",
      " 'question': 'Which country dispatched regular troops to North America?',\n",
      " 'title': 'Seven_Years%27_War'}\n"
     ]
    }
   ],
   "source": [
    "sample_valid_dataset = next(iter(ds_[\"valid\"]))\n",
    "pprint(sample_valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485f8f8-d5ad-44c6-a3b1-0f4e6871753a",
   "metadata": {},
   "source": [
    "### Parsing the datasets into a Pandas Dataframe\n",
    "\n",
    "#### Creating empty DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc24b4d-8922-4766-a29f-54a1dc41363e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "columns=[\"context\", \"answer\", \"question\"]\n",
    "\n",
    "df_train = pd.DataFrame(columns=columns)\n",
    "df_validation = pd.DataFrame(columns=columns)\n",
    "df_test = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e46fb-3d1b-44f6-b409-8239ef26d33e",
   "metadata": {},
   "source": [
    "#### Defining populate_dataframe function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d97b38-65f9-4c74-9690-713b14909258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def populate_dataframe(dataset: any, dataframe: pd.DataFrame, type_dataset:str) -> tuple:\n",
    "    \n",
    "    print(f\"Populating {type_dataset} dataset...\")\n",
    "\n",
    "    count_long = 0\n",
    "    count_short = 0\n",
    "\n",
    "    for index, val in enumerate(tqdm(dataset)):\n",
    "        context = val[\"context\"]\n",
    "        question = val[\"question\"]\n",
    "        answer = val[\"answers\"][\"text\"][0]\n",
    "        num_of_words = len(answer.split())\n",
    "        if num_of_words >= 7:\n",
    "            count_long += 1\n",
    "            continue\n",
    "        else:\n",
    "            dataframe.loc[count_short] = [context] + [answer] + [question]\n",
    "            count_short += 1\n",
    "\n",
    "    print(f\"Count long answers on {type_dataset} dataset: {count_long}\")\n",
    "    print(f\"Count short answers on {type_dataset} dataset: {count_short}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff709a9-2795-4da7-bbdb-e7e04c150545",
   "metadata": {},
   "source": [
    "#### Populating train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e543a76-fb7d-4d67-a270-dbbe47ff3c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739ac64c3ff94d21a4525b9127a08d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count long answers on train dataset: 7176\n",
      "Count short answers on train dataset: 62903\n"
     ]
    }
   ],
   "source": [
    "populate_dataframe(dataset=ds_[\"train\"], dataframe=df_train, type_dataset=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a23b09-dac7-4bc3-8eb3-54480ef30a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances: (62903, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of instances: {df_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d0a06-87d1-4250-a80b-17a7a3539ef4",
   "metadata": {},
   "source": [
    "#### Populating validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b4acb5-a5a7-4e2f-aec9-e2b454be5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating validation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e54362088e40ba8a7f08814b08a67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count long answers on validation dataset: 843\n",
      "Count short answers on validation dataset: 7917\n"
     ]
    }
   ],
   "source": [
    "populate_dataframe(dataset=ds_[\"valid\"], dataframe=df_validation, type_dataset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c6e2402-1eaf-4e3f-9994-d4aa0ca920f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances: (7917, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of instances: {df_validation.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c30540-7192-4636-ac9f-739dec74ddde",
   "metadata": {},
   "source": [
    "#### Populating test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c3874ca-fb86-4d44-af33-e2d54b8e5064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating test dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bc1d14b3ab4bb089f116d8214ea729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count long answers on test dataset: 916\n",
      "Count short answers on test dataset: 7844\n"
     ]
    }
   ],
   "source": [
    "populate_dataframe(dataset=ds_[\"test\"], dataframe=df_test, type_dataset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2559a347-e662-4a4d-9841-ceeba1afa399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances: (7844, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of instances: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc2eb2d-177d-401d-bd8a-b93a7840df6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe shape: (62903, 3)\n",
      "Validation dataframe shape: (7917, 3)\n",
      "Test dataframe shape: (7844, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = shuffle(df_train)\n",
    "df_validation = shuffle(df_validation)\n",
    "df_test = shuffle(df_test)\n",
    "\n",
    "print(f\"Train dataframe shape: {df_train.shape}\")\n",
    "print(f\"Validation dataframe shape: {df_validation.shape}\")\n",
    "print(f\"Test dataframe shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba091541-8b43-408b-a7fd-d3dfd6419563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12678</th>\n",
       "      <td>By 1640, the town's theocratic government and nine-square grid plan were in place, and the town was renamed Newhaven from Quinnipiac. However, the area north of New Haven remained Quinnipiac until 1678, when it was renamed Hamden. The settlement became the headquarters of the New Haven Colony. At the time, the New Haven Colony was separate from the Connecticut Colony, which had been established to the north centering on Hartford. One of the principal differences between the two colonies was that the New Haven colony was an intolerant theocracy that did not permit other churches to be established, while the Connecticut colony permitted the establishment of other churches.</td>\n",
       "      <td>Hamden</td>\n",
       "      <td>In 1678 what was  the new name of the Northern part of New Haven?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48986</th>\n",
       "      <td>By 1885, a new summer retreat was contemplated. That summer, the Bells had a vacation on Cape Breton Island in Nova Scotia, spending time at the small village of Baddeck. Returning in 1886, Bell started building an estate on a point across from Baddeck, overlooking Bras d'Or Lake. By 1889, a large house, christened The Lodge was completed and two years later, a larger complex of buildings, including a new laboratory, were begun that the Bells would name Beinn Bhreagh (Gaelic: beautiful mountain) after Bell's ancestral Scottish highlands.[N 21] Bell also built the Bell Boatyard on the estate, employing up to 40 people building experimental craft as well as wartime lifeboats and workboats for the Royal Canadian Navy and pleasure craft for the Bell family. An enthusiastic boater, Bell and his family sailed or rowed a long series of vessels on Bras d'Or Lake, ordering additional vessels from the H.W. Embree and Sons boatyard in Port Hawkesbury, Nova Scotia. In his final, and some of his most productive years, Bell split his residency between Washington, D.C., where he and his family initially resided for most of the year, and at Beinn Bhreagh where they spent increasing amounts of time.</td>\n",
       "      <td>40</td>\n",
       "      <td>How many people worked for the Bell Boatyard?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>Both Locke and Rousseau developed social contract theories in Two Treatises of Government and Discourse on Inequality, respectively. While quite different works, Locke, Hobbes, and Rousseau agreed that a social contract, in which the government's authority lies in the consent of the governed, is necessary for man to live in civil society. Locke defines the state of nature as a condition in which humans are rational and follow natural law; in which all men are born equal and with the right to life, liberty and property. However, when one citizen breaks the Law of Nature, both the transgressor and the victim enter into a state of war, from which it is virtually impossible to break free. Therefore, Locke said that individuals enter into civil society to protect their natural rights via an \"unbiased judge\" or common authority, such as courts, to appeal to. Contrastingly, Rousseau's conception relies on the supposition that \"civil man\" is corrupted, while \"natural man\" has no want he cannot fulfill himself. Natural man is only taken out of the state of nature when the inequality associated with private property is established. Rousseau said that people join into civil society via the social contract to achieve unity while preserving individual freedom. This is embodied in the sovereignty of the general will, the moral and collective legislative body constituted by citizens.</td>\n",
       "      <td>Rousseau</td>\n",
       "      <td>Who wrote Discourse on Inequality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>During World War II, Imperial Japan invaded most of the former western colonies. The ShÅwa occupation regime committed violent actions against civilians such as the Manila massacre and the implementation of a system of forced labour, such as the one involving 4 to 10 million romusha in Indonesia. A later UN report stated that four million people died in Indonesia as a result of famine and forced labour during the Japanese occupation. The Allied powers who defeated Japan in the South-East Asian theatre of World War II then contended with nationalists to whom the occupation authorities had granted independence.</td>\n",
       "      <td>4 to 10 million</td>\n",
       "      <td>According to the UN report, what was the count of people who perished due to famine?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55669</th>\n",
       "      <td>Among Christians, the Pew Research survey found that 74% were Protestant, 25% were Catholic, and 1% belonged to other Christian denominations, including a small Orthodox Christian community. In terms of Nigeria's major ethnic groups, the Hausa ethnic group (predominant in the north) was found to be 95% Muslim and 5% Christian, the Yoruba tribe (predominant in the west) was 55% Muslim, 35% Christian and 10% adherents of other religions, while the Igbos (predominant in the east) and the Ijaw (south) were 98% Christian, with 2% practising traditional religions. The middle belt of Nigeria contains the largest number of minority ethnic groups in Nigeria, who were found to be mostly Christians and members of traditional religions, with a small proportion of Muslims.</td>\n",
       "      <td>1%</td>\n",
       "      <td>How many Nigerian Christians are Orthodox and other sects?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               context  \\\n",
       "12678                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          By 1640, the town's theocratic government and nine-square grid plan were in place, and the town was renamed Newhaven from Quinnipiac. However, the area north of New Haven remained Quinnipiac until 1678, when it was renamed Hamden. The settlement became the headquarters of the New Haven Colony. At the time, the New Haven Colony was separate from the Connecticut Colony, which had been established to the north centering on Hartford. One of the principal differences between the two colonies was that the New Haven colony was an intolerant theocracy that did not permit other churches to be established, while the Connecticut colony permitted the establishment of other churches.   \n",
       "48986                                                                                                                                                                                                By 1885, a new summer retreat was contemplated. That summer, the Bells had a vacation on Cape Breton Island in Nova Scotia, spending time at the small village of Baddeck. Returning in 1886, Bell started building an estate on a point across from Baddeck, overlooking Bras d'Or Lake. By 1889, a large house, christened The Lodge was completed and two years later, a larger complex of buildings, including a new laboratory, were begun that the Bells would name Beinn Bhreagh (Gaelic: beautiful mountain) after Bell's ancestral Scottish highlands.[N 21] Bell also built the Bell Boatyard on the estate, employing up to 40 people building experimental craft as well as wartime lifeboats and workboats for the Royal Canadian Navy and pleasure craft for the Bell family. An enthusiastic boater, Bell and his family sailed or rowed a long series of vessels on Bras d'Or Lake, ordering additional vessels from the H.W. Embree and Sons boatyard in Port Hawkesbury, Nova Scotia. In his final, and some of his most productive years, Bell split his residency between Washington, D.C., where he and his family initially resided for most of the year, and at Beinn Bhreagh where they spent increasing amounts of time.   \n",
       "8406   Both Locke and Rousseau developed social contract theories in Two Treatises of Government and Discourse on Inequality, respectively. While quite different works, Locke, Hobbes, and Rousseau agreed that a social contract, in which the government's authority lies in the consent of the governed, is necessary for man to live in civil society. Locke defines the state of nature as a condition in which humans are rational and follow natural law; in which all men are born equal and with the right to life, liberty and property. However, when one citizen breaks the Law of Nature, both the transgressor and the victim enter into a state of war, from which it is virtually impossible to break free. Therefore, Locke said that individuals enter into civil society to protect their natural rights via an \"unbiased judge\" or common authority, such as courts, to appeal to. Contrastingly, Rousseau's conception relies on the supposition that \"civil man\" is corrupted, while \"natural man\" has no want he cannot fulfill himself. Natural man is only taken out of the state of nature when the inequality associated with private property is established. Rousseau said that people join into civil society via the social contract to achieve unity while preserving individual freedom. This is embodied in the sovereignty of the general will, the moral and collective legislative body constituted by citizens.   \n",
       "2592                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          During World War II, Imperial Japan invaded most of the former western colonies. The ShÅwa occupation regime committed violent actions against civilians such as the Manila massacre and the implementation of a system of forced labour, such as the one involving 4 to 10 million romusha in Indonesia. A later UN report stated that four million people died in Indonesia as a result of famine and forced labour during the Japanese occupation. The Allied powers who defeated Japan in the South-East Asian theatre of World War II then contended with nationalists to whom the occupation authorities had granted independence.   \n",
       "55669                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Among Christians, the Pew Research survey found that 74% were Protestant, 25% were Catholic, and 1% belonged to other Christian denominations, including a small Orthodox Christian community. In terms of Nigeria's major ethnic groups, the Hausa ethnic group (predominant in the north) was found to be 95% Muslim and 5% Christian, the Yoruba tribe (predominant in the west) was 55% Muslim, 35% Christian and 10% adherents of other religions, while the Igbos (predominant in the east) and the Ijaw (south) were 98% Christian, with 2% practising traditional religions. The middle belt of Nigeria contains the largest number of minority ethnic groups in Nigeria, who were found to be mostly Christians and members of traditional religions, with a small proportion of Muslims.   \n",
       "\n",
       "                answer  \\\n",
       "12678           Hamden   \n",
       "48986               40   \n",
       "8406          Rousseau   \n",
       "2592   4 to 10 million   \n",
       "55669               1%   \n",
       "\n",
       "                                                                                   question  \n",
       "12678                     In 1678 what was  the new name of the Northern part of New Haven?  \n",
       "48986                                         How many people worked for the Bell Boatyard?  \n",
       "8406                                                     Who wrote Discourse on Inequality?  \n",
       "2592   According to the UN report, what was the count of people who perished due to famine?  \n",
       "55669                            How many Nigerian Christians are Orthodox and other sects?  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0040efa7-a358-4552-aab3-3d6fa639fa4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>Dog behavior is the internally coordinated responses (actions or inactions) of the domestic dog (individuals or groups) to internal and/or external stimuli. As the oldest domesticated species, with estimates ranging from 9,000â30,000 years BCE, the minds of dogs inevitably have been shaped by millennia of contact with humans. As a result of this physical and social evolution, dogs, more than any other species, have acquired the ability to understand and communicate with humans and they are uniquely attuned to our behaviors. Behavioral scientists have uncovered a surprising set of social-cognitive abilities in the otherwise humble domestic dog. These abilities are not possessed by the dog's closest canine relatives nor by other highly intelligent mammals such as great apes. Rather, these skills parallel some of the social-cognitive skills of human children.</td>\n",
       "      <td>humans.</td>\n",
       "      <td>Dogs are  very well attuned to what other species' behaviors?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>Midway through the 19th century, the focus of geology shifted from description and classification to attempts to understand how the surface of the Earth had changed. The first comprehensive theories of mountain building were proposed during this period, as were the first modern theories of earthquakes and volcanoes. Louis Agassiz and others established the reality of continent-covering ice ages, and \"fluvialists\" like Andrew Crombie Ramsay argued that river valleys were formed, over millions of years by the rivers that flow through them. After the discovery of radioactivity, radiometric dating methods were developed, starting in the 20th century. Alfred Wegener's theory of \"continental drift\" was widely dismissed when he proposed it in the 1910s, but new data gathered in the 1950s and 1960s led to the theory of plate tectonics, which provided a plausible mechanism for it. Plate tectonics also provided a unified explanation for a wide range of seemingly unrelated geological phenomena. Since 1970 it has served as the unifying principle in geology.</td>\n",
       "      <td>fluvialists</td>\n",
       "      <td>What group did Andrew Crombie Ramsay belong to?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7367</th>\n",
       "      <td>High speed Internet connectivity has become more widely available at a reasonable cost and the cost of video capture and display technology has decreased. Consequently, personal videoconferencing systems based on a webcam, personal computer system, software compression and broadband Internet connectivity have become affordable to the general public. Also, the hardware used for this technology has continued to improve in quality, and prices have dropped dramatically. The availability of freeware (often as part of chat programs) has made software based videoconferencing accessible to many.</td>\n",
       "      <td>chat programs</td>\n",
       "      <td>Videoconferencing freeware is widely available in what programs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>Victoria was pleased when Gladstone resigned in 1885 after his budget was defeated. She thought his government was \"the worst I have ever had\", and blamed him for the death of General Gordon at Khartoum. Gladstone was replaced by Lord Salisbury. Salisbury's government only lasted a few months, however, and Victoria was forced to recall Gladstone, whom she referred to as a \"half crazy &amp; really in many ways ridiculous old man\". Gladstone attempted to pass a bill granting Ireland home rule, but to Victoria's glee it was defeated. In the ensuing election, Gladstone's party lost to Salisbury's and the government switched hands again.</td>\n",
       "      <td>1885</td>\n",
       "      <td>When did Gladstone resign?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>Within a population, it is common for different ages and/or sexes to have different patterns of timing and distance. Female chaffinches Fringilla coelebs in Eastern Fennoscandia migrate earlier in the autumn than males do.</td>\n",
       "      <td>autumn</td>\n",
       "      <td>When do the chaffinches Fringilla coelebs migrate?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    context  \\\n",
       "3968                                                                                                                                                                                                   Dog behavior is the internally coordinated responses (actions or inactions) of the domestic dog (individuals or groups) to internal and/or external stimuli. As the oldest domesticated species, with estimates ranging from 9,000â30,000 years BCE, the minds of dogs inevitably have been shaped by millennia of contact with humans. As a result of this physical and social evolution, dogs, more than any other species, have acquired the ability to understand and communicate with humans and they are uniquely attuned to our behaviors. Behavioral scientists have uncovered a surprising set of social-cognitive abilities in the otherwise humble domestic dog. These abilities are not possessed by the dog's closest canine relatives nor by other highly intelligent mammals such as great apes. Rather, these skills parallel some of the social-cognitive skills of human children.   \n",
       "2013  Midway through the 19th century, the focus of geology shifted from description and classification to attempts to understand how the surface of the Earth had changed. The first comprehensive theories of mountain building were proposed during this period, as were the first modern theories of earthquakes and volcanoes. Louis Agassiz and others established the reality of continent-covering ice ages, and \"fluvialists\" like Andrew Crombie Ramsay argued that river valleys were formed, over millions of years by the rivers that flow through them. After the discovery of radioactivity, radiometric dating methods were developed, starting in the 20th century. Alfred Wegener's theory of \"continental drift\" was widely dismissed when he proposed it in the 1910s, but new data gathered in the 1950s and 1960s led to the theory of plate tectonics, which provided a plausible mechanism for it. Plate tectonics also provided a unified explanation for a wide range of seemingly unrelated geological phenomena. Since 1970 it has served as the unifying principle in geology.   \n",
       "7367                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     High speed Internet connectivity has become more widely available at a reasonable cost and the cost of video capture and display technology has decreased. Consequently, personal videoconferencing systems based on a webcam, personal computer system, software compression and broadband Internet connectivity have become affordable to the general public. Also, the hardware used for this technology has continued to improve in quality, and prices have dropped dramatically. The availability of freeware (often as part of chat programs) has made software based videoconferencing accessible to many.   \n",
       "3084                                                                                                                                                                                                                                                                                                                                                                                                                                           Victoria was pleased when Gladstone resigned in 1885 after his budget was defeated. She thought his government was \"the worst I have ever had\", and blamed him for the death of General Gordon at Khartoum. Gladstone was replaced by Lord Salisbury. Salisbury's government only lasted a few months, however, and Victoria was forced to recall Gladstone, whom she referred to as a \"half crazy & really in many ways ridiculous old man\". Gladstone attempted to pass a bill granting Ireland home rule, but to Victoria's glee it was defeated. In the ensuing election, Gladstone's party lost to Salisbury's and the government switched hands again.   \n",
       "2434                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Within a population, it is common for different ages and/or sexes to have different patterns of timing and distance. Female chaffinches Fringilla coelebs in Eastern Fennoscandia migrate earlier in the autumn than males do.   \n",
       "\n",
       "             answer  \\\n",
       "3968        humans.   \n",
       "2013    fluvialists   \n",
       "7367  chat programs   \n",
       "3084           1885   \n",
       "2434         autumn   \n",
       "\n",
       "                                                              question  \n",
       "3968     Dogs are  very well attuned to what other species' behaviors?  \n",
       "2013                   What group did Andrew Crombie Ramsay belong to?  \n",
       "7367  Videoconferencing freeware is widely available in what programs?  \n",
       "3084                                        When did Gladstone resign?  \n",
       "2434                When do the chaffinches Fringilla coelebs migrate?  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018c99db-beb9-4073-ad40-f818da571663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>Incandescent light bulbs come in a range of shapes and sizes. The names of the shapes may be slightly different in some regions. Many of these shapes have a designation consisting of one or more letters followed by one or more numbers, e.g. A55 or PAR38. The letters represent the shape of the bulb. The numbers represent the maximum diameter, either in 1â8 of an inch, or in millimeters, depending on the shape and the region. For example, 63 mm reflectors are designated R63, but in the US, they are known as R20 (2.5 in). However, in both regions, a PAR38 reflector is known as PAR38.</td>\n",
       "      <td>the maximum diameter</td>\n",
       "      <td>What do the numbers identify in a bulb shape designation?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>In 885 AD the Armenians reestablished themselves as a sovereign kingdom under the leadership of Ashot I of the Bagratid Dynasty. A considerable portion of the Armenian nobility and peasantry fled the Byzantine occupation of Bagratid Armenia in 1045, and the subsequent invasion of the region by Seljuk Turks in 1064. They settled in large numbers in Cilicia, an Anatolian region where Armenians were already established as a minority since Roman times. In 1080, they founded an independent Armenian Principality then Kingdom of Cilicia, which became the focus of Armenian nationalism. The Armenians developed close social, cultural, military, and religious ties with nearby Crusader States, but eventually succumbed to Mamluk invasions. In the next few centuries, Djenghis Khan, Timurids, and the tribal Turkic federations of the Ak Koyunlu and the Kara Koyunlu ruled over the Armenians.</td>\n",
       "      <td>the Bagratid Dynasty</td>\n",
       "      <td>What dynasty was Ashot I part of?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Timber was the chief building material during the Han dynasty; it was used to build palace halls, multi-story residential towers and halls and single-story houses. Because wood decays rapidly, the only remaining evidence of Han wooden architecture is a collection of scattered ceramic roof tiles. The oldest surviving wooden halls in China date to the Tang dynasty (618â907 AD). Architectural historian Robert L. Thorp points out the scarcity of Han-era archaeological remains, and claims that often unreliable Han-era literary and artistic sources are used by historians for clues about lost Han architecture.</td>\n",
       "      <td>907 AD</td>\n",
       "      <td>What is considered to be the last year of the Tang dynasty?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>Federalism also finds expression in ecclesiology (the doctrine of the church). For example, presbyterian church governance resembles parliamentary republicanism (a form of political federalism) to a large extent. In Presbyterian denominations, the local church is ruled by elected elders, some of which are ministerial. Each church then sends representatives or commissioners to presbyteries and further to a general assembly. Each greater level of assembly has ruling authority over its constituent members. In this governmental structure, each component has some level of sovereignty over itself. As in political federalism, in presbyterian ecclesiology there is shared sovereignty.</td>\n",
       "      <td>authority over its constituent members</td>\n",
       "      <td>What does each greater level of assembly have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>The first legislation providing federal authority for regulating pesticides was enacted in 1910; however, decades later during the 1940s manufacturers began to produce large amounts of synthetic pesticides and their use became widespread. Some sources consider the 1940s and 1950s to have been the start of the \"pesticide era.\" Although the U.S. Environmental Protection Agency was established in 1970 and amendments to the pesticide law in 1972, pesticide use has increased 50-fold since 1950 and 2.3 million tonnes (2.5 million short tons) of industrial pesticides are now[when?] used each year. Seventy-five percent of all pesticides in the world are used in developed countries, but use in developing countries is increasing. A study of USA pesticide use trends through 1997 was published in 2003 by the National Science Foundation's Center for Integrated Pest Management.</td>\n",
       "      <td>USA</td>\n",
       "      <td>Trends about use of pesticides have been published from which country?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      context  \\\n",
       "1824                                                                                                                                                                                                                                                                                                              Incandescent light bulbs come in a range of shapes and sizes. The names of the shapes may be slightly different in some regions. Many of these shapes have a designation consisting of one or more letters followed by one or more numbers, e.g. A55 or PAR38. The letters represent the shape of the bulb. The numbers represent the maximum diameter, either in 1â8 of an inch, or in millimeters, depending on the shape and the region. For example, 63 mm reflectors are designated R63, but in the US, they are known as R20 (2.5 in). However, in both regions, a PAR38 reflector is known as PAR38.   \n",
       "3160  In 885 AD the Armenians reestablished themselves as a sovereign kingdom under the leadership of Ashot I of the Bagratid Dynasty. A considerable portion of the Armenian nobility and peasantry fled the Byzantine occupation of Bagratid Armenia in 1045, and the subsequent invasion of the region by Seljuk Turks in 1064. They settled in large numbers in Cilicia, an Anatolian region where Armenians were already established as a minority since Roman times. In 1080, they founded an independent Armenian Principality then Kingdom of Cilicia, which became the focus of Armenian nationalism. The Armenians developed close social, cultural, military, and religious ties with nearby Crusader States, but eventually succumbed to Mamluk invasions. In the next few centuries, Djenghis Khan, Timurids, and the tribal Turkic federations of the Ak Koyunlu and the Kara Koyunlu ruled over the Armenians.   \n",
       "394                                                                                                                                                                                                                                                                                        Timber was the chief building material during the Han dynasty; it was used to build palace halls, multi-story residential towers and halls and single-story houses. Because wood decays rapidly, the only remaining evidence of Han wooden architecture is a collection of scattered ceramic roof tiles. The oldest surviving wooden halls in China date to the Tang dynasty (618â907 AD). Architectural historian Robert L. Thorp points out the scarcity of Han-era archaeological remains, and claims that often unreliable Han-era literary and artistic sources are used by historians for clues about lost Han architecture.   \n",
       "6115                                                                                                                                                                                                             Federalism also finds expression in ecclesiology (the doctrine of the church). For example, presbyterian church governance resembles parliamentary republicanism (a form of political federalism) to a large extent. In Presbyterian denominations, the local church is ruled by elected elders, some of which are ministerial. Each church then sends representatives or commissioners to presbyteries and further to a general assembly. Each greater level of assembly has ruling authority over its constituent members. In this governmental structure, each component has some level of sovereignty over itself. As in political federalism, in presbyterian ecclesiology there is shared sovereignty.   \n",
       "7453             The first legislation providing federal authority for regulating pesticides was enacted in 1910; however, decades later during the 1940s manufacturers began to produce large amounts of synthetic pesticides and their use became widespread. Some sources consider the 1940s and 1950s to have been the start of the \"pesticide era.\" Although the U.S. Environmental Protection Agency was established in 1970 and amendments to the pesticide law in 1972, pesticide use has increased 50-fold since 1950 and 2.3 million tonnes (2.5 million short tons) of industrial pesticides are now[when?] used each year. Seventy-five percent of all pesticides in the world are used in developed countries, but use in developing countries is increasing. A study of USA pesticide use trends through 1997 was published in 2003 by the National Science Foundation's Center for Integrated Pest Management.   \n",
       "\n",
       "                                      answer  \\\n",
       "1824                    the maximum diameter   \n",
       "3160                    the Bagratid Dynasty   \n",
       "394                                   907 AD   \n",
       "6115  authority over its constituent members   \n",
       "7453                                     USA   \n",
       "\n",
       "                                                                    question  \n",
       "1824               What do the numbers identify in a bulb shape designation?  \n",
       "3160                                       What dynasty was Ashot I part of?  \n",
       "394              What is considered to be the last year of the Tang dynasty?  \n",
       "6115                          What does each greater level of assembly have?  \n",
       "7453  Trends about use of pesticides have been published from which country?  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766fc1e-04cc-44f4-969f-83f478f6e004",
   "metadata": {},
   "source": [
    "#### Saving datasets into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81a5c9df-295a-44d3-8d48-f74734626e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_path = \"t5/dataset\"\n",
    "train_ds_file = \"squad_train.csv\"\n",
    "validation_ds_file = \"squad_validation.csv\"\n",
    "test_ds_file = \"squad_test.csv\"\n",
    "\n",
    "df_train.to_csv(f\"{ds_path}/{train_ds_file}\", index=False)\n",
    "df_validation.to_csv(f\"{ds_path}/{validation_ds_file}\", index=False)\n",
    "df_test.to_csv(f\"{ds_path}/{test_ds_file}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8871ec1-b4a1-4db5-992e-5f17cb789e80",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd1296-a827-46b0-b45c-6f794c28a531",
   "metadata": {},
   "source": [
    "Checking GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9946189-b58d-4621-9f75-cd124f47968e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 15 21:44:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   52C    P8    17W / 140W |      1MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c39950-3407-4dc7-8009-bdb65dc74517",
   "metadata": {},
   "source": [
    "### Defining class to handle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933cbe6d-f5ca-4962-8deb-3f5060c863aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuestionGenerationDataset(Dataset):\n",
    "        def __init__(self, tokenizer, file_path, nrows=1000, max_len_input=512, max_len_output=96):\n",
    "            self.file_path = file_path\n",
    "            self.context = \"context\"\n",
    "            self.answer = \"answer\"\n",
    "            self.question = \"question\"\n",
    "            self.data = pd.read_csv(self.file_path, nrows=nrows)\n",
    "            self.max_len_input = max_len_input\n",
    "            self.max_len_output = max_len_output\n",
    "            self.tokenizer = tokenizer\n",
    "            self.inputs = []\n",
    "            self.plain_text_inputs = []\n",
    "            self.targets = []\n",
    "            self.plain_text_target = []\n",
    "            self.skippedcount = 0\n",
    "            self._build()\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.inputs)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            source_ids = self.inputs[idx][\"input_ids\"].squeeze()\n",
    "            target_ids = self.targets[idx][\"input_ids\"].squeeze()\n",
    "            \n",
    "            src_mask = self.inputs[idx][\"attention_mask\"].squeeze()\n",
    "            target_mask = self.targets[idx][\"attention_mask\"].squeeze()\n",
    "    \n",
    "            labels = copy.deepcopy(target_ids)\n",
    "            labels[labels == 0] = -100\n",
    "            \n",
    "            return {\n",
    "                \"source_ids\": source_ids,\n",
    "                \"source_mask\": src_mask,\n",
    "                \"target_ids\": target_ids,\n",
    "                \"target_mask\": target_mask,\n",
    "                \"labels\": labels,\n",
    "                \"plain_text_inputs\": self.plain_text_inputs[idx],\n",
    "                \"plain_text_target\": self.plain_text_target[idx]\n",
    "            }\n",
    "        \n",
    "        def _build(self):\n",
    "            for idx in tqdm(range(len(self.data))):\n",
    "                context = self.data.loc[idx, self.context]\n",
    "                answer = self.data.loc[idx, self.answer]\n",
    "                target = self.data.loc[idx, self.question]\n",
    "                \n",
    "                input_ = f\"context: {context} answer: {answer}\"\n",
    "                target_ = f\"question: {(str(target))}\"\n",
    "            \n",
    "                test_input_encoding = self.tokenizer.encode_plus(input_,\n",
    "                                                                 truncation=False,\n",
    "                                                                 return_tensors=\"pt\")\n",
    "                \n",
    "                length_of_input_encoding = len(test_input_encoding[\"input_ids\"][0])\n",
    "                \n",
    "                if length_of_input_encoding > self.max_len_input:\n",
    "                    self.skippedcount += 1\n",
    "                    continue\n",
    "                \n",
    "                tokenized_inputs = self.tokenizer.batch_encode_plus([input_], \n",
    "                                                                    max_length=self.max_len_input, \n",
    "                                                                    padding=\"max_length\",\n",
    "                                                                    return_tensors=\"pt\")\n",
    "                \n",
    "                tokenized_targets = self.tokenizer.batch_encode_plus([target_],\n",
    "                                                                    max_length=self.max_len_output,\n",
    "                                                                    padding=\"max_length\",\n",
    "                                                                    return_tensors=\"pt\")\n",
    "                \n",
    "                self.inputs.append(tokenized_inputs)\n",
    "                self.plain_text_inputs.append(input_)\n",
    "                self.targets.append(tokenized_targets)\n",
    "                self.plain_text_target.append(target_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9541a36-b24a-40f6-a124-f048dac9f6e3",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5061d1e6-e9c3-4f48-9dcd-e0509479418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 hyper_params, \n",
    "                 model, \n",
    "                 tokenizer,\n",
    "                 train_dataset,\n",
    "                 validation_dataset, \n",
    "                 test_dataset):\n",
    "        \n",
    "        super(T5Model, self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train_dataset = train_dataset\n",
    "        self.validation_dataset = validation_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.targets = []\n",
    "        self.predictions = []\n",
    "        self.mer_scores_per_epoch = []\n",
    "        \n",
    "    def forward(self,\n",
    "                input_ids, \n",
    "                attention_mask=None, \n",
    "                decoder_input_ids=None, \n",
    "                decoder_attention_mask=None, \n",
    "                labels=None):\n",
    "        \n",
    "        outputs = self.model(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             decoder_attention_mask=decoder_attention_mask,\n",
    "                             labels=labels)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(input_ids=batch[\"source_ids\"],\n",
    "                              attention_mask=batch[\"source_mask\"],\n",
    "                              decoder_input_ids=batch[\"target_ids\"],\n",
    "                              decoder_attention_mask=batch[\"target_mask\"],\n",
    "                              labels=batch[\"labels\"])\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=self.hyper_params[\"batch_size\"])\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(input_ids=batch[\"source_ids\"],\n",
    "                              attention_mask=batch[\"source_mask\"],\n",
    "                              decoder_input_ids=batch[\"target_ids\"],\n",
    "                              decoder_attention_mask=batch[\"target_mask\"],\n",
    "                              labels=batch[\"labels\"])\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=self.hyper_params[\"batch_size\"])\n",
    "        \n",
    "        # Get prediction to be calculated\n",
    "        beam_outputs = self.model.generate(input_ids=batch[\"source_ids\"],\n",
    "                                           attention_mask=batch[\"source_mask\"],\n",
    "                                           max_length=72,\n",
    "                                           early_stopping=True,\n",
    "                                           num_beams=5,\n",
    "                                           num_return_sequences=1)\n",
    "        \n",
    "        for beam_output in beam_outputs:\n",
    "            prediction_sentence = self.tokenizer.decode(beam_output,\n",
    "                                    skip_special_tokens=True,\n",
    "                                    clean_up_tokenization_spaces=True)\n",
    "        \n",
    "            self.predictions.append(prediction_sentence)\n",
    "        \n",
    "        self.targets = batch[\"plain_text_target\"] \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(input_ids=batch[\"source_ids\"],\n",
    "                              attention_mask=batch[\"source_mask\"],\n",
    "                              decoder_input_ids=batch[\"target_ids\"],\n",
    "                              decoder_attention_mask=batch[\"target_mask\"],\n",
    "                              labels=batch[\"labels\"])\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        \n",
    "        # Get prediction to be calculated\n",
    "        beam_outputs = self.model.generate(input_ids=batch[\"source_ids\"],\n",
    "                                           attention_mask=batch[\"source_mask\"],\n",
    "                                           max_length=72,\n",
    "                                           early_stopping=True,\n",
    "                                           num_beams=5,\n",
    "                                           num_return_sequences=1)\n",
    "        prediction_sentences = []\n",
    "        \n",
    "        for beam_output in beam_outputs:\n",
    "        \n",
    "            prediction_sentence = self.tokenizer.decode(beam_output,\n",
    "                                    skip_special_tokens=True,\n",
    "                                    clean_up_tokenization_spaces=True)\n",
    "            \n",
    "            prediction_sentences.append(prediction_sentence)\n",
    "  \n",
    "        mer = MatchErrorRate()\n",
    "        mer_score = mer(prediction_sentences, batch[\"plain_text_target\"])\n",
    "        self.log(\"test_mer_score\", mer_score, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        \n",
    "        bleu = BLEUScore()\n",
    "        bleu_score = bleu(prediction_sentences, [[i] for i in batch[\"plain_text_target\"]])\n",
    "        self.log(\"test_bleu_score\", bleu_score, on_step=False, on_epoch=True, prog_bar=True, batch_size=1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        mer = MatchErrorRate()\n",
    "        mer_score = mer(self.predictions, self.targets)\n",
    "        self.log(\"val_mer_score\", mer_score, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        bleu = BLEUScore()\n",
    "        bleu_score = bleu(self.predictions, [[i] for i in self.targets])\n",
    "        self.log(\"val_bleu_score\", bleu_score, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        self.targets = []\n",
    "        self.predictions = []\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, \n",
    "                          batch_size=self.hyper_params[\"batch_size\"], \n",
    "                          num_workers=self.hyper_params[\"num_workers\"])\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.validation_dataset, \n",
    "                          batch_size=self.hyper_params[\"batch_size\"], \n",
    "                          num_workers=self.hyper_params[\"num_workers\"])\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, \n",
    "                          batch_size=1, \n",
    "                          num_workers=self.hyper_params[\"num_workers\"])\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), \n",
    "                          lr=self.hyper_params[\"learning_rate\"], eps=self.hyper_params[\"epsilon\"])\n",
    "        return optimizer\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92063b31-3d9e-4c2d-b3a8-70b0caf72907",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f95891-d77a-4abb-9b85-f2e4ec3d85ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f86bb62e8f548a0ba9e9a7cdd803a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492064c58d294a93bd0b52a81d0d1497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba826874bf74527807eca6123847be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"batch_size\": 4,\n",
    "    \"num_workers\": 4,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"epsilon\": 1e-8,\n",
    "    \"max_epochs\": 10,\n",
    "    \"max_len_input\": 512, \n",
    "    \"max_len_output\": 96,\n",
    "    \"num_rows_train\": 12000,\n",
    "    \"num_rows_validation\": 1200,\n",
    "    \"num_rows_test\": 1200,\n",
    "    \"train_file_path\": \"t5/dataset/squad_train.csv\",\n",
    "    \"validation_file_path\": \"t5/dataset/squad_validation.csv\",\n",
    "    \"test_file_path\": \"t5/dataset/squad_test.csv\",\n",
    "    \"model_file_path\": \"t5/model\",\n",
    "    \"tokenizer_file_path\": \"t5/tokenizer\"\n",
    "}\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model_config = T5Config(decoder_start_token_id=t5_tokenizer.convert_tokens_to_ids(['<pad>'])[0])\n",
    "t5_model = T5ForConditionalGeneration(model_config)\n",
    "\n",
    "train_dataset = QuestionGenerationDataset(tokenizer=t5_tokenizer,\n",
    "                                          file_path=config[\"train_file_path\"],\n",
    "                                          max_len_input=config[\"max_len_input\"],\n",
    "                                          max_len_output=config[\"max_len_output\"],\n",
    "                                          nrows=config[\"num_rows_train\"])\n",
    "\n",
    "validation_dataset = QuestionGenerationDataset(tokenizer=t5_tokenizer, \n",
    "                                               file_path=config[\"validation_file_path\"],\n",
    "                                               max_len_input=config[\"max_len_input\"],\n",
    "                                               max_len_output=config[\"max_len_output\"],     \n",
    "                                               nrows=config[\"num_rows_validation\"])\n",
    "\n",
    "test_dataset = QuestionGenerationDataset(tokenizer=t5_tokenizer, \n",
    "                                               file_path=config[\"test_file_path\"],\n",
    "                                               max_len_input=config[\"max_len_input\"],\n",
    "                                               max_len_output=config[\"max_len_output\"],     \n",
    "                                               nrows=config[\"num_rows_test\"])\n",
    "\n",
    "model = T5Model(hyper_params=config,\n",
    "               model=t5_model,\n",
    "               tokenizer=t5_tokenizer,\n",
    "               train_dataset=train_dataset,\n",
    "               validation_dataset=validation_dataset,\n",
    "               test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f3367e2b-79b9-4e9b-8f08-0be90ebeb92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e19f1a3be6744f1ad992c986df4b084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('t5/tokenizer/tokenizer_config.json',\n",
       " 't5/tokenizer/special_tokens_map.json',\n",
       " 't5/tokenizer/spiece.model',\n",
       " 't5/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=config[\"max_epochs\"],\n",
    "                     accelerator=\"auto\",\n",
    "                     callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "print(\"Saving model\")\n",
    "model.model.save_pretrained(config[\"model_file_path\"])\n",
    "t5_tokenizer.save_pretrained(config[\"tokenizer_file_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac344de5-a703-47f6-a951-ad4adb041d50",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "852ce821-9946-43bb-9215-6a0cf6445e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c8ed33446b4f439ff2acdc5c66e6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\">        Test metric        </span>â<span style=\"font-weight: bold\">       DataLoader 0        </span>â\n",
       "â¡ââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\">      test_bleu_score      </span>â<span style=\"color: #800080; text-decoration-color: #800080\">   0.014201955869793892    </span>â\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>â<span style=\"color: #800080; text-decoration-color: #800080\">     4.341996192932129     </span>â\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\">      test_mer_score       </span>â<span style=\"color: #800080; text-decoration-color: #800080\">    0.8047617077827454     </span>â\n",
       "âââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡ââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â\u001b[36m \u001b[0m\u001b[36m     test_bleu_score     \u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m  0.014201955869793892   \u001b[0m\u001b[35m \u001b[0mâ\n",
       "â\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m    4.341996192932129    \u001b[0m\u001b[35m \u001b[0mâ\n",
       "â\u001b[36m \u001b[0m\u001b[36m     test_mer_score      \u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m   0.8047617077827454    \u001b[0m\u001b[35m \u001b[0mâ\n",
       "âââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 4.341996192932129,\n",
       "  'test_mer_score': 0.8047617077827454,\n",
       "  'test_bleu_score': 0.014201955869793892}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b0002cf-6f05-4d72-b7e4-e9a6ad7b39d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Num of epochs</th>\n",
       "      <th>Data points</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_len_input</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_mer_score</th>\n",
       "      <th>test_bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exp_1</td>\n",
       "      <td>10</td>\n",
       "      <td>Train: 1000, Val: 100, Test: 100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>512</td>\n",
       "      <td>5.391</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.0091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exp_2</td>\n",
       "      <td>10</td>\n",
       "      <td>Train: 1000, Val: 100, Test: 100</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>512</td>\n",
       "      <td>5.697</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp_3</td>\n",
       "      <td>10</td>\n",
       "      <td>Train: 1000, Val: 100, Test: 100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>512</td>\n",
       "      <td>6.223</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exp_4</td>\n",
       "      <td>10</td>\n",
       "      <td>Train: 1000, Val: 100, Test: 100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>256</td>\n",
       "      <td>5.638</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exp_5</td>\n",
       "      <td>10</td>\n",
       "      <td>Train: 20000, Val: 2000, Test: 2000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>512</td>\n",
       "      <td>4.341</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experiment  Num of epochs                          Data points  batch_size  \\\n",
       "0      exp_1             10     Train: 1000, Val: 100, Test: 100           4   \n",
       "1      exp_2             10     Train: 1000, Val: 100, Test: 100          16   \n",
       "2      exp_3             10     Train: 1000, Val: 100, Test: 100           4   \n",
       "3      exp_4             10     Train: 1000, Val: 100, Test: 100           4   \n",
       "4      exp_5             10  Train: 20000, Val: 2000, Test: 2000           4   \n",
       "\n",
       "   learning_rate  max_len_input  test_loss  test_mer_score  test_bleu_score  \n",
       "0        0.00030            512      5.391           0.787           0.0091  \n",
       "1        0.00030            512      5.697           0.819           0.0080  \n",
       "2        0.00002            512      6.223           0.792           0.0164  \n",
       "3        0.00010            256      5.638           0.814           0.0081  \n",
       "4        0.00002            512      4.341           0.804           0.0142  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = {\n",
    "    \"Experiment\": [\"exp_1\", \"exp_2\", \"exp_3\", \"exp_4\", \"exp_5\"],\n",
    "    \"Num of epochs\": [10, 10, 10, 10, 10],\n",
    "    \"Data points\": [\"Train: 1000, Val: 100, Test: 100\", \n",
    "                    \"Train: 1000, Val: 100, Test: 100\", \n",
    "                    \"Train: 1000, Val: 100, Test: 100\", \n",
    "                    \"Train: 1000, Val: 100, Test: 100\",\n",
    "                    \"Train: 20000, Val: 2000, Test: 2000\"],\n",
    "    \"batch_size\": [4, 16, 4, 4, 4],\n",
    "    \"learning_rate\": [3e-4, 3e-4, 2e-5, 1e-4, 2e-5],\n",
    "    \"max_len_input\": [512, 512, 512, 256, 512],\n",
    "    \"test_loss\": [5.391, 5.697, 6.223, 5.638, 4.341],\n",
    "    \"test_mer_score\": [0.787, 0.819, 0.792, 0.814, 0.804],\n",
    "    \"test_bleu_score\": [0.0091, 0.0080, 0.0164, 0.0081, 0.01420],\n",
    "}\n",
    "\n",
    "pd.DataFrame(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f56782b-ed08-41b4-9aed-e6694f0c6550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"trained_model_path\": \"t5/model\",\n",
    "    \"trained_tokenizer\": \"t5/tokenizer\"\n",
    "}\n",
    "\n",
    "saved_model = T5ForConditionalGeneration.from_pretrained(test_config[\"trained_model_path\"])\n",
    "saved_tokenizer = T5Tokenizer.from_pretrained(test_config[\"trained_tokenizer\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "test_model = saved_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "513023f8-19ab-4490-8714-880598ad93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5.py:219: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questions from context: The Social Dilemma, released in 2020, talks about the rise of social media and how it affects societyâs minds as a whole. It is a docudrama film directed by Jeff Orlowski and covered various social media aspects talking about how it manipulates individualsâ minds if not used correctly.\n",
      "question: What is the name of the a name of the film's name?\n",
      "answer: The Social Dilemma\n",
      "question: What is the name of the a name of the film's film?\n",
      "answer: The Social Dilemma\n",
      "question: What is the name of the a name of the film's film'?\n",
      "answer: The Social Dilemma\n",
      "------------------------------\n",
      "Generating questions from context: It is more than likely that you will not see references to training, validation, and test datasets in modern applied machine learning.\n",
      "question: What is the name of a term for s?\n",
      "answer: training, validation, and test datasets\n",
      "question: What is the name of the a term for s?\n",
      "answer: training, validation, and test datasets\n",
      "question: What is the name of the a term for s that can be used to?\n",
      "answer: training, validation, and test datasets\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def set_input_structure(context, answer):\n",
    "    return f\"context: {context} answer: {answer} </s>\"\n",
    "\n",
    "\n",
    "def generate_questions(model, tokenizer, context, answer):\n",
    "\n",
    "    text = set_input_structure(context, answer)\n",
    "    encoding = saved_tokenizer.encode_plus(text, max_length=512, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "    input_ids, attention_mask = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    test_model.eval()\n",
    "    beam_outputs = model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  max_length=72,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=3)\n",
    "\n",
    "    print(\"Generating questions from context:\", context)\n",
    "    \n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output,\n",
    "                                skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "        print(sent)\n",
    "        print(\"answer:\", answer)\n",
    "        \n",
    "    print(\"-\" * 30)\n",
    "        \n",
    "        \n",
    "test_data = [\n",
    "    { \n",
    "        \"context\": \"The Social Dilemma, released in 2020, talks about the rise of social media and how it affects societyâs minds as a whole. It is a docudrama film directed by Jeff Orlowski and covered various social media aspects talking about how it manipulates individualsâ minds if not used correctly.\", \n",
    "        \"answer\": \"The Social Dilemma\"\n",
    "    },\n",
    "    { \n",
    "        \"context\": \"It is more than likely that you will not see references to training, validation, and test datasets in modern applied machine learning.\", \n",
    "        \"answer\": \"training, validation, and test datasets\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i in test_data:\n",
    "    generate_questions(test_model, saved_tokenizer, i[\"context\"], i[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5df08a9a-fecf-428d-a386-5883c58ffda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning_logs/\n",
      "lightning_logs/version_8/\n",
      "lightning_logs/version_8/events.out.tfevents.1697501095.nbz72pdid3.59.13\n",
      "lightning_logs/version_8/hparams.yaml\n",
      "lightning_logs/version_8/checkpoints/\n",
      "lightning_logs/version_8/checkpoints/epoch=9-step=49840.ckpt\n",
      "lightning_logs/version_8/events.out.tfevents.1697511609.nbz72pdid3.59.14\n",
      "t5/\n",
      "t5/tokenizer/\n",
      "t5/tokenizer/tokenizer_config.json\n",
      "t5/tokenizer/special_tokens_map.json\n",
      "t5/tokenizer/spiece.model\n",
      "t5/model/\n",
      "t5/model/pytorch_model.bin\n",
      "t5/model/config.json\n",
      "t5/dataset/\n",
      "t5/dataset/squad_validation.csv\n",
      "t5/dataset/squad_train.csv\n",
      "t5/dataset/squad_test.csv\n",
      "requirements.txt\n",
      "T5-Model-QG-Custom.ipynb\n"
     ]
    }
   ],
   "source": [
    "#!tar -czvf custom_model__10_16_2023.tar.gz lightning_logs t5 requirements.txt T5-Model-QG-Custom.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc96bbe2-2d34-4aeb-a2ef-d1f48a02886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: The third war of the Diadochi broke out because of the growing power and ambition of Antigonus. He began removing and appointing satraps as if he were king and also raided the royal treasuries in Ectabana, Persepolis and Susa, making off with 25,000 talents. Seleucus was forced to flee to Egypt and Antigonus was soon at war with Ptolemy, Lysimachus, and Cassander. He then invaded Phoenicia, laid siege to Tyre, stormed Gaza and began building a fleet. Ptolemy invaded Syria and defeated Antigonus' son, Demetrius Poliorcetes, in the Battle of Gaza of 312 BC which allowed Seleucus to secure control of Babylonia, and the eastern satrapies. In 310, Cassander had young King Alexander IV and his mother Roxane murdered, ending the Argead Dynasty which had ruled Macedon for several centuries. answer: 25,000\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: How many talents did Diadochi steal from Ectabana, Persepolis and Susa?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What was the name of the Athanasi?\n",
      "\t 1.- question: What was the name of the Athanasiusususususususususususus?\n",
      "\t 2.- question: What was the name of the Athanasiususususususususususususus?\n",
      "\n",
      "\n",
      "1.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: The fauna in the state is just as diverse as the flora and varies greatly due to the large contrast in climates. In the mountain zone of the state the most observed mammals are: Mexican fox squirrel (Sciurus nayaritensis), antelope jackrabbit (Lepus alleni), raccoon (Procyon lotor), hooded skunk (Mephitis macroura), wild boar (Sus scrofa), collared peccary (Pecari tajacu), white-tailed deer (Odocoileus virginianus), mule deer Odocoileus hemionus, American bison Bison bison, cougar (Puma concolor), eastern cottontail Sylvilagus floridanus, North American porcupine Erethizon dorsatum, bobcat Lynx rufus, Mexican wolf Canis lupus baileyi, and coyote Canis latrans. American black bear Ursus americanus is also found but in very small numbers. The Mexican wolf, once abundant, has been extirpated. The main cause of degradation has been grazing. Although there are many reptilian species in the mountains the most observed species include: Northern Mexican pine snake, Pituophis deppei jani, Texas horned lizard (Phrynosoma cornutum), rock rattlesnake (Crotalus lepidus), black-tailed rattlesnake (Crotalus molossus), and plateau tiger salamander Ambystoma velasci, one of possibly many amphibians to be found in the mountains. answer: American black bear\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: Ursus Americanus is what animal that is found in relatively small numbers?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What is the name of the sids?\n",
      "\t 1.- question: What is the name of the a sidsi?\n",
      "\t 2.- question: What is the name of the term for the s of a s that can be found in the world?\n",
      "\n",
      "\n",
      "2.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: The remaining band members recorded \"Independent Women Part I\", which appeared on the soundtrack to the 2000 film, Charlie's Angels. It became their best-charting single, topping the U.S. Billboard Hot 100 chart for eleven consecutive weeks. In early 2001, while Destiny's Child was completing their third album, BeyoncÃ© landed a major role in the MTV made-for-television film, Carmen: A Hip Hopera, starring alongside American actor Mekhi Phifer. Set in Philadelphia, the film is a modern interpretation of the 19th century opera Carmen by French composer Georges Bizet. When the third album Survivor was released in May 2001, Luckett and Roberson filed a lawsuit claiming that the songs were aimed at them. The album debuted at number one on the U.S. Billboard 200, with first-week sales of 663,000 copies sold. The album spawned other number-one hits, \"Bootylicious\" and the title track, \"Survivor\", the latter of which earned the group a Grammy Award for Best R&B Performance by a Duo or Group with Vocals. After releasing their holiday album 8 Days of Christmas in October 2001, the group announced a hiatus to further pursue solo careers. answer: eleven\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: How many weeks did their single \"Independent Women Part I\" stay on top?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What was the name of BeyoncÃ©'s first album?\n",
      "\t 1.- question: What was the name of Beyonce's first album?\n",
      "\t 2.- question: What was the name of BeyoncÃ©'s first film?\n",
      "\n",
      "\n",
      "3.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: Special bundles of the game contain a Wolf Link Amiibo figurine, which unlocks a Wii U-exclusive dungeon called the \"Cave of Shadows\" and can carry data over to the upcoming 2016 Zelda game. Other Zelda-related Amiibo figurines have distinct functions: Link and Toon Link replenish arrows, Zelda and Sheik restore Link's health, and Ganondorf causes Link to take twice as much damage. answer: Wolf Link Amiibo figurine\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: What special item is included with certain versions of Twilight Princess HD?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What is the name of the sioon?\n",
      "\t 1.- question: What is the name of the sioa?\n",
      "\t 2.- question: What is the name of the sia ion?\n",
      "\n",
      "\n",
      "4.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: In fledgling democracies funding can also be provided by foreign aid. International donors provide financing to political parties in developing countries as a means to promote democracy and good governance. Support can be purely financial or otherwise. Frequently it is provided as capacity development activities including the development of party manifestos, party constitutions and campaigning skills. Developing links between ideologically linked parties is another common feature of international support for a party. Sometimes this can be perceived as directly supporting the political aims of a political party, such as the support of the US government to the Georgian party behind the Rose Revolution. Other donors work on a more neutral basis, where multiple donors provide grants in countries accessible by all parties for various aims defined by the recipients. There have been calls by leading development think-tanks, such as the Overseas Development Institute, to increase support to political parties as part of developing the capacity to deal with the demands of interest-driven donors to improve governance. answer: to increase support to political parties\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: What does the overseas development institute want to do?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What is the name of the a result of the a result of the a result of a result of a result of a result of the a result of a result of a result of a result of a result of a result of a result of a result of a result of\n",
      "\t 1.- question: What is the name of the a result of the a result of the a result of a result of a result of a result of a result of the a result of a result of a result of a result of a result of a result of a result of a result of\n",
      "\t 2.- question: What is the name of the a result of the a result of the a result of a result of a result of a result of the a result of a result of a result of a result of a result of a result of a result of a result?\n",
      "\n",
      "\n",
      "5.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: From 2001 to 2008, Mac sales increased continuously on an annual basis. Apple reported worldwide sales of 3.36 million Macs during the 2009 holiday season. As of Mid-2011, the Macintosh continues to enjoy rapid market share increase in the US, growing from 7.3% of all computer shipments in 2010 to 9.3% in 2011. According to IDC's quarterly PC tracker, globally, in 3rd quarter of 2014, Apple's PC market share increased 5.7 percent year over year, with record sales of 5.5 million units. Apple now sits in the number five spot, with a global market share of about 6% during 2014, behind Lenovo, HP, Dell and Acer. answer: 7.3%\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: What was Apples market share of all computer shipments in 2010?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What is the name of the based in the world?\n",
      "\t 1.- question: What is the name of the based on the world?\n",
      "\t 2.- question: What is the name of the based on the a result of based on American Idol?\n",
      "\n",
      "\n",
      "6.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: In 2012, the government of St. Helena funded the creation of the St. Helena Human Rights Action Plan 2012-2015. Work is being done under this action plan, including publishing awareness-raising articles in local newspapers, providing support for members of the public with human rights queries, and extending several UN Conventions on human rights to St. Helena. answer: with human rights queries\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: How was support for members of the public given?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What is the name of the largest in the United States?\n",
      "\t 1.- question: What is the name of the based on?\n",
      "\t 2.- question: What is the name of the largest in the world?\n",
      "\n",
      "\n",
      "7.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: After World War I the US Army started developing a dual-role (AA/ground) automatic 37 mm cannon, designed by John M. Browning. It was standardised in 1927 as the T9 AA cannon, but trials quickly revealed that it was worthless in the ground role. However, while the shell was a bit light (well under 2 lbs) it had a good effective ceiling and fired 125 rounds per minute; an AA carriage was developed and it entered service in 1939. The Browning 37mm proved prone to jamming, and was eventually replaced in AA units by the Bofors 40 mm. The Bofors had attracted attention from the US Navy, but none were acquired before 1939. Also, in 1931 the US Army worked on a mobile anti-aircraft machine mount on the back of a heavy truck having four .30 caliber water-cooled machine guns and an optical director. It proved unsuccessful and was abandoned. answer: 125\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: How many rounds did this cannon fire per second?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What was the name of the U.S.S.?\n",
      "\t 1.- question: What was the name of the U.S.?\n",
      "\t 2.- question: What was the name of the U.S.S.S.?\n",
      "\n",
      "\n",
      "8.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: Areas such as South Street and Old City have a vibrant night life. The Avenue of the Arts in Center City contains many restaurants and theaters, such as the Kimmel Center for the Performing Arts, which is home to the Philadelphia Orchestra, generally considered one of the top five orchestras in the United States, and the Academy of Music, the nation's oldest continually operating opera house, home to the Opera Company of Philadelphia and the Pennsylvania Ballet. The Wilma Theatre and Philadelphia Theatre Company have new buildings constructed in the last decade on the avenue. They produce a variety of new works. Several blocks to the east are the Walnut Street Theatre, America's oldest theatre and the largest subscription theater in the world; as well as the Lantern Theatre at St. Stephens Church, one of a number of smaller venues. answer: Kimmel Center for the Performing Arts\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: What is the home of the orchestra?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What is the name of the world's population?\n",
      "\t 1.- question: What is the name of the world's population in the world?\n",
      "\t 2.- question: What is the name of the world's largest in the world?\n",
      "\n",
      "\n",
      "9.- Context and Answer ----------------------------------------------------------------------------------------------------\n",
      "context: Both Rousseau and Locke's social contract theories rest on the presupposition of natural rights, which are not a result of law or custom, but are things that all men have in pre-political societies, and are therefore universal and inalienable. The most famous natural right formulation comes from John Locke in his Second Treatise, when he introduces the state of nature. For Locke the law of nature is grounded on mutual security, or the idea that one cannot infringe on another's natural rights, as every man is equal and has the same inalienable rights. These natural rights include perfect equality and freedom, and the right to preserve life and property. Locke also argued against slavery on the basis that enslaving yourself goes against the law of nature; you cannot surrender your own rights, your freedom is absolute and no one can take it from you. Additionally, Locke argues that one person cannot enslave another because it is morally reprehensible, although he introduces a caveat by saying that enslavement of a lawful captive in time of war would not go against one's natural rights. answer: because it is morally reprehensible\n",
      "Target ---------------------------------------------------------------------------------------------------------------\n",
      "\t question: Why did John Locke believe that one person cannot enslave another?\n",
      "Text Generated -------------------------------------------------------------------------------------------------------\n",
      "\t 0.- question: What is the name of the a result of a result of s'?\n",
      "\t 1.- question: What is the name of the a result of a result of a result of?\n",
      "\t 2.- question: What is the name of the a result of a result of a result of s'?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_questions_from_text(model, tokenizer, text):\n",
    "    \n",
    "    encoding = saved_tokenizer.encode_plus(text, max_length=512, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "    input_ids, attention_mask = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    test_model.eval()\n",
    "    beam_outputs = model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  max_length=72,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=3)\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    for beam_output in beam_outputs:\n",
    "        pred = tokenizer.decode(beam_output,\n",
    "                                skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "        preds.append(pred)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "\n",
    "evaluation_data = []\n",
    "\n",
    "for data_point in range(0, 10):\n",
    "    print(f\"{data_point}.- Context and Answer\", \"-\"*100)\n",
    "    text = test_dataset[data_point][\"plain_text_inputs\"]\n",
    "    print(text)\n",
    "    print(\"Target\", \"-\"*111)\n",
    "    print(\"\\t\", test_dataset[data_point][\"plain_text_target\"])\n",
    "    print(\"Text Generated\", \"-\"*103)\n",
    "    preds = generate_questions_from_text(model=test_model, tokenizer=saved_tokenizer, text=text)\n",
    "    for idx, val in enumerate(preds):\n",
    "        \n",
    "        print(\"\\t\", f\"{idx}.- {val}\")\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd239ae0-0e61-4390-94e6-fcbaede0f36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
